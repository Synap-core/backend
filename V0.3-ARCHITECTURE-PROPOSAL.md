# ğŸ—ï¸ Synap Backend V0.3 - Architecture Proposal

**Document Type**: Internal Technical Specification  
**Status**: ğŸŸ¡ DRAFT - Pending Approval  
**Author**: Engineering Team  
**Date**: 2025-11-06  
**Target**: Q1 2025

---

## ğŸ“‹ Executive Summary

**Mission**: Refactor V0.2 to eliminate redundancy, use correct databases for each data type, and establish a clean, scalable architecture.

**Key Changes**:
1. âŒ Remove content_blocks table â†’ âœ… Files on R2/S3 with metadata only
2. âŒ Remove PostgreSQL for events â†’ âœ… Time-series database
3. âŒ Remove @initiativ/storage duplication â†’ âœ… Single source of truth
4. âŒ Remove Inngest projectors â†’ âœ… Direct writes + complex workflows only

**Impact**: 70% storage reduction, 10x scalability improvement, 40% cost reduction

**Timeline**: 3 weeks

**Risk Level**: ğŸŸ¡ Medium (requires data migration)

---

## ğŸ¯ Core Principle: Right Database for Right Data

### The Golden Rule

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EACH DATA TYPE GETS THE OPTIMAL DATABASE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Time-Series Data    â†’ Time-Series Database                  â”‚
â”‚  Relational Data     â†’ PostgreSQL                            â”‚
â”‚  Binary Files        â†’ Object Storage (R2/S3)                â”‚
â”‚  Search Vectors      â†’ Vector Database                       â”‚
â”‚  Cache               â†’ Redis                                 â”‚
â”‚                                                              â”‚
â”‚  âŒ NOT: Everything in PostgreSQL                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Proposed Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATA STORAGE LAYER (Single Source of Truth Per Type)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. EVENTS (Immutable Audit Log)                        â”‚   â”‚
â”‚  â”‚     Database: TimescaleDB or EventStoreDB               â”‚   â”‚
â”‚  â”‚     Schema:                                              â”‚   â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚     â”‚ id           UUID                     â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ aggregateId  UUID    â† REFERENCE     â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ aggregateType TEXT   â† entity/task   â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ eventType    TEXT    â† created/updatedâ”‚            â”‚   â”‚
â”‚  â”‚     â”‚ userId       TEXT                     â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ data         JSONB   â† DELTAS ONLY    â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ metadata     JSONB   â† AI model, etc â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ timestamp    TIMESTAMPTZ              â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ version      INTEGER â† Aggregate ver â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ causationId  UUID    â† Which event   â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ correlationId UUID   â† Request trace â”‚            â”‚   â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚     Purpose: Immutable history, audit trail, replay     â”‚   â”‚
â”‚  â”‚     Retention: Infinite (compressed after 90 days)      â”‚   â”‚
â”‚  â”‚     Access: Append-only, sequential reads               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  2. ENTITIES (Current State - Projection)               â”‚   â”‚
â”‚  â”‚     Database: PostgreSQL (Neon)                         â”‚   â”‚
â”‚  â”‚     Schema:                                              â”‚   â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚     â”‚ id           UUID PRIMARY KEY         â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ userId       TEXT NOT NULL            â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ type         TEXT NOT NULL            â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ title        TEXT                     â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ preview      TEXT (200 chars)         â”‚            â”‚   â”‚
â”‚  â”‚     â”‚                                        â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ // File reference (NOT content!)      â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ fileUrl      TEXT     â† R2 URL        â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ filePath     TEXT     â† R2 key        â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ fileSize     INTEGER                  â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ fileType     TEXT     â† md/pdf/audio  â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ checksum     TEXT     â† SHA256        â”‚            â”‚   â”‚
â”‚  â”‚     â”‚                                        â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ version      INTEGER (from events)    â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ createdAt    TIMESTAMPTZ              â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ updatedAt    TIMESTAMPTZ              â”‚            â”‚   â”‚
â”‚  â”‚     â”‚ deletedAt    TIMESTAMPTZ              â”‚            â”‚   â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚     Purpose: Current state, fast queries                â”‚   â”‚
â”‚  â”‚     Rebuilt from: Events (can be regenerated)           â”‚   â”‚
â”‚  â”‚     Access: Read-heavy, occasional writes               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3. FILES (Actual Content)                              â”‚   â”‚
â”‚  â”‚     Storage: Cloudflare R2 (S3-compatible)              â”‚   â”‚
â”‚  â”‚     Structure:                                           â”‚   â”‚
â”‚  â”‚     â””â”€â”€ users/                                           â”‚   â”‚
â”‚  â”‚         â””â”€â”€ {userId}/                                    â”‚   â”‚
â”‚  â”‚             â”œâ”€â”€ notes/                                   â”‚   â”‚
â”‚  â”‚             â”‚   â””â”€â”€ {entityId}.md                        â”‚   â”‚
â”‚  â”‚             â”œâ”€â”€ tasks/                                   â”‚   â”‚
â”‚  â”‚             â”‚   â””â”€â”€ {entityId}.md                        â”‚   â”‚
â”‚  â”‚             â”œâ”€â”€ attachments/                             â”‚   â”‚
â”‚  â”‚             â”‚   â””â”€â”€ {entityId}-{filename}                â”‚   â”‚
â”‚  â”‚             â””â”€â”€ exports/                                 â”‚   â”‚
â”‚  â”‚                 â””â”€â”€ {timestamp}.json                     â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚     Purpose: Actual content storage                      â”‚   â”‚
â”‚  â”‚     Access: Signed URLs (1 hour expiry)                  â”‚   â”‚
â”‚  â”‚     CDN: Cached at edge                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  4. RELATIONS (Knowledge Graph)                         â”‚   â”‚
â”‚  â”‚     Database: PostgreSQL (Neon)                         â”‚   â”‚
â”‚  â”‚     Schema: (unchanged - already correct)                â”‚   â”‚
â”‚  â”‚     Purpose: Links between entities                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  5. SEARCH INDEX (Semantic Search)                      â”‚   â”‚
â”‚  â”‚     Database: pgvector OR Qdrant (decision needed)      â”‚   â”‚
â”‚  â”‚     Purpose: Vector similarity search                    â”‚   â”‚
â”‚  â”‚     Rebuilt from: File content on R2                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  6. CACHE (Optional Performance Layer)                  â”‚   â”‚
â”‚  â”‚     Database: Redis                                      â”‚   â”‚
â”‚  â”‚     Purpose: Hot data, sessions, rate limits             â”‚   â”‚
â”‚  â”‚     TTL: 5-60 minutes                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Insight**: âŒ **NO content_blocks table!**
- Content lives in R2/S3
- entities table stores metadata + file reference
- Events reference entities by ID

---

## ğŸ” Technical Decisions to Make

### Decision #1: Time-Series Database for Events

**Requirements**:
- âœ… Append-only writes (no updates)
- âœ… Time-range queries (get events from X to Y)
- âœ… Compression (old events compressed)
- âœ… Retention policies (archive after 1 year)
- âœ… Real-time streams (subscribe to new events)
- âœ… Event replay (rebuild projections)

---

#### Option A: TimescaleDB â­â­â­â­â­ **RECOMMENDED**

**What Is It**: PostgreSQL extension for time-series data

**Pros**:
- âœ… Compatible with Neon (just enable extension)
- âœ… Use same database (simpler ops)
- âœ… Drizzle ORM works (no new client)
- âœ… Automatic compression (10x reduction)
- âœ… Retention policies (auto-delete old data)
- âœ… Continuous aggregates (materialized views)
- âœ… No learning curve (it's still PostgreSQL)

**Cons**:
- âš ï¸ Not all PostgreSQL providers support it (Neon might not)
- âš ï¸ Less specialized than EventStoreDB

**Schema Example**:
```sql
-- Enable extension
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- Create events table
CREATE TABLE events (
  id UUID DEFAULT gen_random_uuid(),
  timestamp TIMESTAMPTZ NOT NULL,
  aggregate_id UUID NOT NULL,
  aggregate_type TEXT NOT NULL,
  event_type TEXT NOT NULL,
  user_id TEXT NOT NULL,
  data JSONB NOT NULL,
  metadata JSONB,
  version INTEGER NOT NULL,
  causation_id UUID,
  correlation_id UUID
);

-- Convert to hypertable (time-series magic!)
SELECT create_hypertable('events', 'timestamp');

-- Compression policy (compress after 7 days)
ALTER TABLE events SET (
  timescaledb.compress,
  timescaledb.compress_segmentby = 'user_id, aggregate_id'
);

SELECT add_compression_policy('events', INTERVAL '7 days');

-- Retention policy (keep last 2 years)
SELECT add_retention_policy('events', INTERVAL '2 years');

-- Continuous aggregate (pre-computed stats)
CREATE MATERIALIZED VIEW events_hourly
WITH (timescaledb.continuous) AS
SELECT
  time_bucket('1 hour', timestamp) AS hour,
  user_id,
  event_type,
  count(*) as count
FROM events
GROUP BY hour, user_id, event_type;
```

**Migration**:
```typescript
// Check if Neon supports TimescaleDB
// If not, use separate TimescaleDB instance
```

**Verdict**: â­â­â­â­â­ **Best if Neon supports it**

---

#### Option B: EventStoreDB â­â­â­â­â­ **BEST for Event Sourcing**

**What Is It**: Purpose-built database for event sourcing

**Pros**:
- âœ… Built SPECIFICALLY for event sourcing
- âœ… Real-time event streams (native)
- âœ… Projections built-in
- âœ… Optimistic concurrency native
- âœ… Event replay optimized
- âœ… Subscriptions (real-time updates)
- âœ… Clustering (high availability)
- âœ… Scales to billions of events

**Cons**:
- âš ï¸ Separate service to manage
- âš ï¸ New client library to learn
- âš ï¸ Can't use Drizzle ORM
- âš ï¸ Operational complexity

**Schema Example**:
```typescript
import { EventStoreDBClient, jsonEvent } from '@eventstore/db-client';

const client = EventStoreDBClient.connectionString(
  'esdb://admin:changeit@localhost:2113?tls=false'
);

// Append event to stream
await client.appendToStream('entity-123', [
  jsonEvent({
    type: 'title_changed',
    data: {
      oldValue: 'Draft',
      newValue: 'Final',
    },
    metadata: {
      userId: 'user-456',
      timestamp: new Date().toISOString(),
    },
  }),
]);

// Read stream
const events = client.readStream('entity-123');
for await (const event of events) {
  console.log(event);
}

// Subscribe to all events (REAL-TIME!)
const subscription = client.subscribeToAll();
for await (const event of subscription) {
  // Update projections in real-time
  await updateProjection(event);
}
```

**Verdict**: â­â­â­â­â­ **Best for true event sourcing**

---

#### Option C: ClickHouse â­â­â­â­

**What Is It**: Columnar database for analytics

**Pros**:
- âœ… Insanely fast for append-only (100K writes/sec)
- âœ… Excellent compression (10-20x)
- âœ… SQL interface (familiar)
- âœ… Time-series queries optimized
- âœ… Scales to petabytes

**Cons**:
- âš ï¸ No updates/deletes (perfect for events!)
- âš ï¸ Eventually consistent
- âš ï¸ More complex queries
- âš ï¸ Operational overhead

**Verdict**: â­â­â­â­ **Good for analytics, overkill for events**

---

#### Option D: Keep PostgreSQL + Partitioning â­â­â­

**What Is It**: Use PostgreSQL with table partitioning

**Pros**:
- âœ… No new technology
- âœ… Works with current setup
- âœ… Drizzle ORM compatible

**Cons**:
- âš ï¸ Still not optimal for time-series
- âš ï¸ Manual partition management
- âš ï¸ Won't scale to 100M+ events
- âš ï¸ No real-time streams

**Verdict**: â­â­â­ **Only if budget-constrained**

---

### ğŸ¯ RECOMMENDATION: TimescaleDB (if supported) OR EventStoreDB

**Decision Matrix**:

| Factor | TimescaleDB | EventStoreDB |
|--------|-------------|--------------|
| **Ease of adoption** | âœ…âœ…âœ…âœ…âœ… | âœ…âœ…âœ… |
| **Event sourcing features** | âœ…âœ…âœ… | âœ…âœ…âœ…âœ…âœ… |
| **Operational complexity** | âœ…âœ…âœ…âœ…âœ… | âœ…âœ…âœ… |
| **Scalability** | âœ…âœ…âœ…âœ… | âœ…âœ…âœ…âœ…âœ… |
| **Cost** | âœ…âœ…âœ…âœ… | âœ…âœ…âœ… |

**Recommendation**: 
1. **Try TimescaleDB first** (if Neon supports)
2. **Fall back to EventStoreDB** (if not)

---

## ğŸ—‚ï¸ Revised Database Schema

### 1. Events Table (Time-Series DB)

```sql
-- TimescaleDB or EventStoreDB

CREATE TABLE events (
  -- Identity
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  
  -- Aggregate (what object this event is about)
  aggregate_id UUID NOT NULL,        -- âœ… REFERENCE to entity
  aggregate_type TEXT NOT NULL,      -- 'entity' | 'relation' | 'user'
  
  -- Event classification
  event_type TEXT NOT NULL,          -- Enum: see below
  
  -- Ownership
  user_id TEXT NOT NULL,             -- Who triggered this event
  
  -- Event data (DELTAS ONLY, NOT FULL OBJECTS!)
  data JSONB NOT NULL,               -- What changed
  metadata JSONB,                    -- Context (AI model, IP, etc.)
  
  -- Timing
  timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  
  -- Event sourcing
  version INTEGER NOT NULL,          -- Aggregate version (optimistic locking)
  causation_id UUID,                 -- Which event caused this
  correlation_id UUID,               -- Request tracing
  
  -- Source
  source TEXT NOT NULL DEFAULT 'api' -- 'api' | 'automation' | 'sync'
);

-- TimescaleDB: Convert to hypertable
SELECT create_hypertable('events', 'timestamp');

-- Indexes
CREATE INDEX idx_events_aggregate ON events(aggregate_id, timestamp DESC);
CREATE INDEX idx_events_user ON events(user_id, timestamp DESC);
CREATE INDEX idx_events_type ON events(event_type);
CREATE INDEX idx_events_correlation ON events(correlation_id) WHERE correlation_id IS NOT NULL;
```

**Example Events**:
```typescript
// Entity created
{
  aggregateId: "entity-123",
  aggregateType: "entity",
  eventType: "entity.created",
  data: {
    type: "note",
    title: "Initial title",
  },
  version: 1
}

// Title changed
{
  aggregateId: "entity-123",
  aggregateType: "entity", 
  eventType: "entity.title_changed",
  data: {
    oldValue: "Initial title",
    newValue: "Updated title"
  },
  version: 2,
  causationId: "evt-user-edit"
}

// File uploaded
{
  aggregateId: "entity-123",
  aggregateType: "entity",
  eventType: "entity.file_uploaded",
  data: {
    fileUrl: "https://r2.../users/abc/notes/123.md",
    fileSize: 1024,
    checksum: "sha256:..."
  },
  version: 3
}
```

**Key Point**: Events are **SMALL** (deltas only), not full objects!

---

### 2. Entities Table (PostgreSQL)

```sql
-- PostgreSQL (Neon) - Current State Projection

CREATE TABLE entities (
  -- Identity
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id TEXT NOT NULL,
  
  -- Type
  type TEXT NOT NULL,  -- Enum: 'note' | 'task' | 'project' | 'page'
  
  -- Metadata (for fast queries)
  title TEXT,
  preview TEXT,  -- First 200 chars (extracted from file)
  
  -- File reference (NOT content!)
  file_url TEXT,      -- https://r2.../users/abc/notes/123.md
  file_path TEXT,     -- users/abc/notes/123.md (R2 key)
  file_size INTEGER,  -- Bytes
  file_type TEXT,     -- 'markdown' | 'pdf' | 'audio' | 'video'
  checksum TEXT,      -- SHA256 for change detection
  
  -- Event sourcing
  version INTEGER NOT NULL DEFAULT 1,  -- Matches last event version
  
  -- Timestamps
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  deleted_at TIMESTAMPTZ,  -- Soft delete
  
  -- Constraints
  CONSTRAINT valid_file_type CHECK (file_type IN ('markdown', 'pdf', 'audio', 'video', 'image'))
);

-- Indexes
CREATE INDEX idx_entities_user ON entities(user_id);
CREATE INDEX idx_entities_type ON entities(type);
CREATE INDEX idx_entities_created ON entities(created_at DESC);
CREATE INDEX idx_entities_composite ON entities(user_id, type, created_at DESC);
```

**Key Changes**:
- âŒ Removed: `content` field (lives in R2!)
- âŒ Removed: `embedding` field (separate table or Qdrant)
- âŒ Removed: `storageProvider` (always R2)
- âœ… Added: file reference fields
- âœ… Added: checksum for sync validation

---

### 3. NO content_blocks Table!

**Current (Wrong)**:
```sql
-- âŒ This table is REDUNDANT
CREATE TABLE content_blocks (
  entity_id UUID PRIMARY KEY,
  content TEXT,  -- âŒ Duplication!
  embedding vector(1536),
  storage_provider TEXT,
  storage_path TEXT,
  ...
);
```

**Correct (V0.3)**:
```
âŒ Table deleted entirely!

âœ… Content lives in: R2 files
âœ… File reference in: entities.file_url
âœ… Embeddings in: separate vectors table OR Qdrant
```

**Rationale**:
- Content should NEVER be in relational DB (large, unstructured)
- File storage (R2/S3) is 10x cheaper for blobs
- Easier to backup, replicate, CDN cache

---

### 4. Search Vectors (Separate from Content)

```sql
-- Option A: PostgreSQL table with pgvector
CREATE TABLE entity_vectors (
  entity_id UUID PRIMARY KEY REFERENCES entities(id) ON DELETE CASCADE,
  user_id TEXT NOT NULL,  -- For filtering
  
  -- Embedding
  embedding vector(1536),
  embedding_model TEXT DEFAULT 'text-embedding-3-small',
  
  -- Metadata for search
  entity_type TEXT,
  title TEXT,  -- Denormalized for search results
  
  -- Timestamps
  indexed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  
  CONSTRAINT fk_entity FOREIGN KEY (entity_id) REFERENCES entities(id)
);

-- HNSW index for fast similarity search
CREATE INDEX idx_vectors_embedding ON entity_vectors 
  USING hnsw (embedding vector_cosine_ops);

-- User isolation
CREATE INDEX idx_vectors_user ON entity_vectors(user_id);
```

**Embedding Workflow**:
```
1. File uploaded to R2
2. Content extracted from R2
3. OpenAI generates embedding
4. Embedding saved to entity_vectors
5. Search queries use HNSW index
```

---

#### Alternative: Qdrant Vector Database â­â­â­â­

**Pros**:
- âœ… Purpose-built for vectors
- âœ… Faster than pgvector (benchmarks)
- âœ… Better filtering
- âœ… Cloud-native

**Cons**:
- âš ï¸ Another service
- âš ï¸ New API client

**When to Use**: If >1M vectors

---

### 5. Component Tables (Unchanged)

```sql
-- task_details (already correct)
CREATE TABLE task_details (
  entity_id UUID PRIMARY KEY REFERENCES entities(id),
  status TEXT NOT NULL DEFAULT 'todo',
  priority INTEGER DEFAULT 0,
  due_date TIMESTAMPTZ,
  completed_at TIMESTAMPTZ
);

-- tags (already correct with userId)
CREATE TABLE tags (
  id UUID PRIMARY KEY,
  user_id TEXT NOT NULL,
  name TEXT NOT NULL,
  color TEXT,
  UNIQUE(user_id, name)
);

-- entity_tags (already correct)
CREATE TABLE entity_tags (
  entity_id UUID REFERENCES entities(id) ON DELETE CASCADE,
  tag_id UUID REFERENCES tags(id) ON DELETE CASCADE,
  PRIMARY KEY (entity_id, tag_id)
);

-- relations (already correct)
CREATE TABLE relations (
  id UUID PRIMARY KEY,
  user_id TEXT NOT NULL,
  source_entity_id UUID REFERENCES entities(id),
  target_entity_id UUID REFERENCES entities(id),
  type TEXT NOT NULL
);
```

---

## ğŸ“ Type System & Standardization

### Core Type Hierarchy

```typescript
// ===================================================================
// ENUMS (Standardized, Extensible)
// ===================================================================

/**
 * Aggregate Types (DDD Aggregates)
 */
export enum AggregateType {
  ENTITY = 'entity',
  RELATION = 'relation',
  USER = 'user',
}

/**
 * Entity Types (Specific entity kinds)
 */
export enum EntityType {
  NOTE = 'note',
  TASK = 'task',
  PROJECT = 'project',
  PAGE = 'page',
  EVENT = 'event',
  IDEA = 'idea',
}

/**
 * Event Types (Domain Events)
 * 
 * Pattern: {aggregate}.{action}[.{detail}]
 */
export enum EventType {
  // Entity lifecycle
  ENTITY_CREATED = 'entity.created',
  ENTITY_UPDATED = 'entity.updated',
  ENTITY_DELETED = 'entity.deleted',
  
  // Entity properties
  ENTITY_TITLE_CHANGED = 'entity.title_changed',
  ENTITY_TYPE_CHANGED = 'entity.type_changed',
  ENTITY_FILE_UPLOADED = 'entity.file_uploaded',
  ENTITY_FILE_DELETED = 'entity.file_deleted',
  
  // Task specific
  TASK_STATUS_CHANGED = 'task.status_changed',
  TASK_COMPLETED = 'task.completed',
  TASK_DUE_DATE_SET = 'task.due_date_set',
  
  // Tags
  ENTITY_TAG_ADDED = 'entity.tag_added',
  ENTITY_TAG_REMOVED = 'entity.tag_removed',
  
  // Relations
  RELATION_CREATED = 'relation.created',
  RELATION_DELETED = 'relation.deleted',
  
  // AI processing
  AI_ANALYSIS_REQUESTED = 'ai.analysis_requested',
  AI_ANALYSIS_COMPLETED = 'ai.analysis_completed',
  AI_ENRICHMENT_APPLIED = 'ai.enrichment_applied',
}

/**
 * File Types
 */
export enum FileType {
  MARKDOWN = 'markdown',
  PDF = 'pdf',
  AUDIO = 'audio',
  VIDEO = 'video',
  IMAGE = 'image',
}

/**
 * Task Status
 */
export enum TaskStatus {
  TODO = 'todo',
  IN_PROGRESS = 'in_progress',
  DONE = 'done',
  CANCELLED = 'cancelled',
}

/**
 * Event Source
 */
export enum EventSource {
  API = 'api',
  AUTOMATION = 'automation',
  SYNC = 'sync',
  MIGRATION = 'migration',
  SYSTEM = 'system',
}

// ===================================================================
// BRANDED TYPES (Prevent ID Mix-ups)
// ===================================================================

export type UserId = string & { readonly __brand: 'UserId' };
export type EntityId = string & { readonly __brand: 'EntityId' };
export type EventId = string & { readonly __brand: 'EventId' };
export type TagId = string & { readonly __brand: 'TagId' };
export type RelationId = string & { readonly __brand: 'RelationId' };

// Constructor functions
export const UserId = (id: string): UserId => id as UserId;
export const EntityId = (id: string): EntityId => id as EntityId;
export const EventId = (id: string): EventId => id as EventId;

// ===================================================================
// EVENT STRUCTURE (DDD Event Pattern)
// ===================================================================

/**
 * Base Event (all events extend this)
 */
export interface BaseEvent {
  id: EventId;
  timestamp: Date;
  userId: UserId;
  
  // Aggregate reference
  aggregateId: EntityId | RelationId | UserId;
  aggregateType: AggregateType;
  aggregateVersion: number;
  
  // Event metadata
  eventType: EventType;
  source: EventSource;
  
  // Tracing
  causationId?: EventId;    // Which event caused this
  correlationId?: string;   // Request trace ID
}

/**
 * Event with typed data payload
 */
export interface DomainEvent<TData = unknown, TMeta = unknown> extends BaseEvent {
  data: TData;
  metadata?: TMeta;
}

/**
 * Specific event types (examples)
 */
export interface EntityCreatedEvent extends DomainEvent<{
  type: EntityType;
  title: string;
  fileUrl?: string;
}> {
  eventType: EventType.ENTITY_CREATED;
  aggregateType: AggregateType.ENTITY;
}

export interface EntityTitleChangedEvent extends DomainEvent<{
  oldValue: string;
  newValue: string;
}> {
  eventType: EventType.ENTITY_TITLE_CHANGED;
  aggregateType: AggregateType.ENTITY;
}

export interface EntityFileUploadedEvent extends DomainEvent<{
  fileUrl: string;
  filePath: string;
  fileSize: number;
  fileType: FileType;
  checksum: string;
}> {
  eventType: EventType.ENTITY_FILE_UPLOADED;
  aggregateType: AggregateType.ENTITY;
}

// ===================================================================
// ENTITY STRUCTURE (Current State)
// ===================================================================

export interface Entity {
  // Identity
  id: EntityId;
  userId: UserId;
  
  // Type
  type: EntityType;
  
  // Metadata
  title: string;
  preview: string;  // First 200 chars
  
  // File reference (NOT content!)
  fileUrl?: string;      // https://r2.../users/abc/notes/123.md
  filePath?: string;     // users/abc/notes/123.md
  fileSize?: number;     // Bytes
  fileType?: FileType;   // markdown, pdf, etc.
  checksum?: string;     // SHA256
  
  // Event sourcing
  version: number;  // Current version (matches last event)
  
  // Timestamps
  createdAt: Date;
  updatedAt: Date;
  deletedAt?: Date;
}

// ===================================================================
// COMPONENT DATA (Task-specific)
// ===================================================================

export interface TaskDetails {
  entityId: EntityId;
  status: TaskStatus;
  priority: number;  // 0-3
  dueDate?: Date;
  completedAt?: Date;
}

// ===================================================================
// RELATIONS (Knowledge Graph)
// ===================================================================

export enum RelationType {
  CONTAINS = 'contains',          // Project contains task
  RELATES_TO = 'relates_to',      // Note relates to note
  BLOCKS = 'blocks',              // Task blocks task
  DUPLICATES = 'duplicates',      // Note duplicates note
  MENTIONS = 'mentions',          // Note mentions entity
  DERIVED_FROM = 'derived_from',  // Note derived from note
}

export interface Relation {
  id: RelationId;
  userId: UserId;
  sourceEntityId: EntityId;
  targetEntityId: EntityId;
  type: RelationType;
  createdAt: Date;
}

// ===================================================================
// VECTOR SEARCH
// ===================================================================

export interface EntityVector {
  entityId: EntityId;
  userId: UserId;
  
  // Embedding
  embedding: number[];  // 1536 dimensions
  embeddingModel: string;
  
  // Denormalized for search results
  entityType: EntityType;
  title: string;
  preview: string;
  
  // Timestamps
  indexedAt: Date;
}
```

---

## ğŸ”„ Revised Data Flow

### Create Note Flow (Correct Architecture)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. USER REQUEST                                             â”‚
â”‚     POST /trpc/notes.create                                  â”‚
â”‚     { content: "Meeting notes" }                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. API HANDLER                                              â”‚
â”‚     â€¢ Validate input (Zod)                                   â”‚
â”‚     â€¢ Extract userId from session                            â”‚
â”‚     â€¢ Generate entityId                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. UPLOAD TO R2                                             â”‚
â”‚     const url = await r2.upload({                            â”‚
â”‚       path: `users/${userId}/notes/${entityId}.md`,          â”‚
â”‚       content: input.content,                                â”‚
â”‚       contentType: 'text/markdown'                           â”‚
â”‚     });                                                      â”‚
â”‚                                                              â”‚
â”‚     Returns: {                                               â”‚
â”‚       url: "https://r2.../users/abc/notes/123.md",          â”‚
â”‚       size: 1024,                                            â”‚
â”‚       checksum: "sha256:..."                                 â”‚
â”‚     }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. WRITE EVENT (Time-Series DB)                             â”‚
â”‚     await events.append({                                    â”‚
â”‚       aggregateId: entityId,                                 â”‚
â”‚       aggregateType: 'entity',                               â”‚
â”‚       eventType: EventType.ENTITY_CREATED,                   â”‚
â”‚       data: {                                                â”‚
â”‚         type: 'note',                                        â”‚
â”‚         title: extractedTitle,                               â”‚
â”‚         fileUrl: url,                                        â”‚
â”‚         fileSize: size,                                      â”‚
â”‚         checksum: checksum                                   â”‚
â”‚       },                                                     â”‚
â”‚       version: 1                                             â”‚
â”‚     });                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. UPDATE PROJECTION (Synchronous - No Inngest!)            â”‚
â”‚     await db.insert(entities).values({                       â”‚
â”‚       id: entityId,                                          â”‚
â”‚       userId: userId,                                        â”‚
â”‚       type: 'note',                                          â”‚
â”‚       title: extractedTitle,                                 â”‚
â”‚       fileUrl: url,        // âœ… Reference                    â”‚
â”‚       fileSize: size,                                        â”‚
â”‚       checksum: checksum,                                    â”‚
â”‚       version: 1                                             â”‚
â”‚     });                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. ASYNC AI ENRICHMENT (Inngest - Complex Workflow!)        â”‚
â”‚     Inngest.send('ai.enrich_requested', {                    â”‚
â”‚       entityId, userId, fileUrl                              â”‚
â”‚     });                                                      â”‚
â”‚                                                              â”‚
â”‚     Inngest workflow:                                        â”‚
â”‚     1. Download from R2                                      â”‚
â”‚     2. Call Claude API                                       â”‚
â”‚     3. Generate embedding (OpenAI)                           â”‚
â”‚     4. Save to entity_vectors                                â”‚
â”‚     5. Emit 'ai.enrichment_completed' event                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Changes**:
- âœ… Content uploaded to R2 FIRST
- âœ… Event stores reference (fileUrl), not content
- âœ… Projection is SYNCHRONOUS (no Inngest delay)
- âœ… Inngest only for COMPLEX operations (AI, embeddings)

**Total Time**: 
- Synchronous: 200ms (upload + DB write)
- Async (AI): 2-3s (user doesn't wait)

---

## ğŸ¯ Inngest Usage (Corrected)

### âŒ Remove: Simple Projectors

```typescript
// âŒ DELETE THIS (too simple for Inngest)
inngest.createFunction(
  { event: 'entity.created' },
  async ({ event }) => {
    await db.insert(entities).values(event.data);
  }
);
```

**Why**: This should be SYNCHRONOUS in API handler!

---

### âœ… Keep: Complex Workflows

```typescript
// âœ… KEEP THIS (true orchestration)
inngest.createFunction(
  { event: 'ai.enrich_requested' },
  async ({ event, step }) => {
    
    // Step 1: Download content from R2 (could fail)
    const content = await step.run('download', async () => {
      return await r2.download(event.data.fileUrl);
    });
    
    // Step 2: AI analysis (expensive, needs retry)
    const analysis = await step.run('ai-analysis', async () => {
      return await claude.analyze(content);
    });
    
    // Step 3: Generate embedding (external API)
    const embedding = await step.run('embedding', async () => {
      return await openai.embed(content);
    });
    
    // Step 4: Save results
    await step.run('save', async () => {
      // Update entity with AI data
      await db.update(entities)
        .set({ title: analysis.title })
        .where(eq(entities.id, event.data.entityId));
      
      // Save embedding
      await db.insert(entityVectors).values({
        entityId: event.data.entityId,
        embedding: embedding,
      });
    });
    
    // Step 5: Emit completion event
    await step.sendEvent('emit-completion', {
      name: EventType.AI_ENRICHMENT_COMPLETED,
      data: {
        entityId: event.data.entityId,
        analysis,
      },
    });
  }
);
```

**Why This Is Correct**:
- âœ… Multiple external API calls
- âœ… Each step can fail and retry
- âœ… Complex orchestration
- âœ… Observable (Inngest dashboard)

---

## ğŸ—„ï¸ Storage Strategy

### File Storage on R2

**Structure**:
```
synap-r2-bucket/
â””â”€â”€ users/
    â””â”€â”€ {userId}/
        â”œâ”€â”€ notes/
        â”‚   â”œâ”€â”€ {entityId}.md
        â”‚   â””â”€â”€ {entityId}.md
        â”œâ”€â”€ tasks/
        â”‚   â””â”€â”€ {entityId}.md
        â”œâ”€â”€ attachments/
        â”‚   â”œâ”€â”€ {entityId}-image.png
        â”‚   â””â”€â”€ {entityId}-doc.pdf
        â””â”€â”€ exports/
            â””â”€â”€ {timestamp}-backup.json
```

**Access Pattern**:
```typescript
// Upload
const result = await r2.upload({
  key: `users/${userId}/notes/${entityId}.md`,
  body: content,
  contentType: 'text/markdown',
});

// Returns:
{
  url: "https://r2.synap.dev/users/abc/notes/123.md",
  size: 1024,
  etag: "abc123...",
  checksum: "sha256:..."
}

// Save reference in DB
await db.insert(entities).values({
  id: entityId,
  fileUrl: result.url,
  fileSize: result.size,
  checksum: result.checksum,
});

// Later: Download
const content = await r2.download(`users/${userId}/notes/${entityId}.md`);

// Or: Generate signed URL (1 hour expiry)
const signedUrl = await r2.getSignedUrl(filePath, { expiresIn: 3600 });
```

**Benefits**:
- âœ… Cheap storage ($0.015/GB vs $0.23/GB PostgreSQL)
- âœ… CDN caching (global distribution)
- âœ… No database bloat
- âœ… Easy backups
- âœ… Version history (R2 supports versioning)

---

## ğŸ”§ Trade-Offs Analysis

### Trade-Off #1: TimescaleDB vs EventStoreDB

| Aspect | TimescaleDB | EventStoreDB | Winner |
|--------|-------------|--------------|---------|
| **Ease of Integration** | âœ…âœ…âœ…âœ…âœ… Same DB | âœ…âœ…âœ… New service | TimescaleDB |
| **Event Sourcing Features** | âœ…âœ…âœ… Good | âœ…âœ…âœ…âœ…âœ… Perfect | EventStoreDB |
| **Operational Complexity** | âœ…âœ…âœ…âœ…âœ… Simple | âœ…âœ…âœ… Moderate | TimescaleDB |
| **Real-Time Streams** | âš ï¸ Via polling | âœ…âœ…âœ…âœ…âœ… Native | EventStoreDB |
| **Learning Curve** | âœ…âœ…âœ…âœ…âœ… None | âœ…âœ…âœ… Some | TimescaleDB |
| **Cost** | âœ…âœ…âœ…âœ… Low | âœ…âœ…âœ… Medium | TimescaleDB |
| **Scalability** | âœ…âœ…âœ…âœ… 10B events | âœ…âœ…âœ…âœ…âœ… 100B+ | EventStoreDB |

**Decision Criteria**:
- **If Neon supports TimescaleDB**: Use TimescaleDB âœ…
- **If not OR need >10B events**: Use EventStoreDB âœ…
- **Budget constrained**: Stay on PostgreSQL (acceptable to 10M events)

**Recommendation**: **Start with TimescaleDB, migrate to EventStoreDB if needed**

---

### Trade-Off #2: pgvector vs Qdrant

| Aspect | pgvector | Qdrant | Winner |
|--------|----------|--------|---------|
| **Integration** | âœ…âœ…âœ…âœ…âœ… Same DB | âœ…âœ…âœ… Separate | pgvector |
| **Performance** | âœ…âœ…âœ…âœ… Good | âœ…âœ…âœ…âœ…âœ… Excellent | Qdrant |
| **Filtering** | âœ…âœ…âœ… Basic | âœ…âœ…âœ…âœ…âœ… Advanced | Qdrant |
| **Ops Complexity** | âœ…âœ…âœ…âœ…âœ… Simple | âœ…âœ…âœ… Moderate | pgvector |
| **Cost** | âœ…âœ…âœ…âœ…âœ… Included | âœ…âœ…âœ… Additional | pgvector |
| **Scale** | âœ…âœ…âœ…âœ… 10M vectors | âœ…âœ…âœ…âœ…âœ… 1B+ | Qdrant |

**Decision Criteria**:
- **<1M vectors**: pgvector âœ…
- **>1M vectors OR advanced filtering**: Qdrant âœ…

**Recommendation**: **pgvector for V0.3, consider Qdrant for V1.0**

---

### Trade-Off #3: Synchronous vs Async Projections

#### Current (V0.2): Async via Inngest

```typescript
// API writes event
await events.append(event);
return { success: true };  // User gets response

// Later: Inngest updates projection
// Delay: 100-500ms
```

**Pros**:
- âœ… Fast API response
- âœ… Retry logic

**Cons**:
- âš ï¸ Eventually consistent
- âš ï¸ User might not see data immediately

---

#### Proposed (V0.3): Synchronous for Simple Ops

```typescript
// API writes event AND projection
await db.transaction(async (tx) => {
  // 1. Write event
  await tx.append(event);
  
  // 2. Update projection
  await tx.insert(entities).values({ ... });
});

return { success: true, entity };  // User gets data immediately
```

**Pros**:
- âœ… Immediate consistency
- âœ… Simpler to reason about
- âœ… No Inngest needed for simple ops

**Cons**:
- âš ï¸ Slightly slower API (50ms vs 10ms)

**Recommendation**: 
- **Simple operations**: Synchronous âœ…
- **Complex operations** (AI, external APIs): Async via Inngest âœ…

---

## ğŸ“ Extensibility Strategy

### How to Add New Entity Types

```typescript
// 1. Add to enum
export enum EntityType {
  NOTE = 'note',
  TASK = 'task',
  // âœ… NEW TYPE
  HABIT = 'habit',
}

// 2. Add component table (if needed)
CREATE TABLE habit_details (
  entity_id UUID PRIMARY KEY REFERENCES entities(id),
  frequency TEXT NOT NULL,  -- 'daily' | 'weekly'
  streak_count INTEGER DEFAULT 0,
  last_completed TIMESTAMPTZ
);

// 3. Add event types
export enum EventType {
  // ... existing
  // âœ… NEW EVENTS
  HABIT_COMPLETED = 'habit.completed',
  HABIT_STREAK_BROKEN = 'habit.streak_broken',
}

// 4. Add handler
async function handleHabitCompleted(event: DomainEvent) {
  await db.insert(habitDetails).values({
    entityId: event.aggregateId,
    lastCompleted: new Date(),
    streakCount: calculateStreak(),
  });
}
```

**Pattern**: Extensible via:
- âœ… Enum additions (type-safe)
- âœ… Component tables (opt-in)
- âœ… Event handlers (pluggable)

**No Over-Engineering**: Only add what's needed

---

### How to Add New Event Types

```typescript
// 1. Define in enum
export enum EventType {
  // âœ… NEW EVENT
  ENTITY_ARCHIVED = 'entity.archived',
}

// 2. Define event interface (optional, for type safety)
export interface EntityArchivedEvent extends DomainEvent<{
  reason?: string;
  archivedBy: UserId;
}> {
  eventType: EventType.ENTITY_ARCHIVED;
}

// 3. Add handler (if projection needed)
switch (event.eventType) {
  case EventType.ENTITY_ARCHIVED:
    return await handleEntityArchived(event);
}

// 4. Emit from code
await events.append({
  eventType: EventType.ENTITY_ARCHIVED,
  aggregateId: entityId,
  data: { reason: 'User archived' },
});
```

---

## ğŸ¯ Migration Strategy (V0.2 â†’ V0.3)

### Phase 1: Add R2 Storage (Week 1)

**Steps**:
```
Day 1: Setup R2, implement upload/download
Day 2: Add file fields to entities table
Day 3: Dual-write (PostgreSQL + R2)
Day 4: Migrate existing content to R2
Day 5: Remove content from content_blocks
Day 6-7: Testing
```

**Code**:
```typescript
// packages/storage/src/r2.ts (NEW)
export class R2Storage {
  async upload(key: string, content: string): Promise<{
    url: string;
    size: number;
    checksum: string;
  }> {
    const response = await fetch(
      `https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/r2/buckets/${BUCKET}/objects/${key}`,
      {
        method: 'PUT',
        body: content,
        headers: { Authorization: `Bearer ${R2_API_TOKEN}` },
      }
    );
    
    return {
      url: `https://r2.synap.dev/${key}`,
      size: Buffer.byteLength(content),
      checksum: await sha256(content),
    };
  }
  
  async download(key: string): Promise<string> {
    const response = await fetch(`https://r2.synap.dev/${key}`);
    return await response.text();
  }
  
  async getSignedUrl(key: string, expiresIn: number): Promise<string> {
    // Generate signed URL with expiry
    return signedUrl;
  }
}
```

**Migration Script**:
```typescript
// scripts/migrate-content-to-r2.ts
async function migrateContentToR2() {
  const entities = await db.select()
    .from(contentBlocks)
    .where(isNotNull(contentBlocks.content));
  
  for (const entity of entities) {
    // Upload to R2
    const result = await r2.upload(
      `users/${entity.userId}/notes/${entity.entityId}.md`,
      entity.content
    );
    
    // Update entities table
    await db.update(entities)
      .set({
        fileUrl: result.url,
        fileSize: result.size,
        checksum: result.checksum,
      })
      .where(eq(entities.id, entity.entityId));
    
    console.log(`âœ… Migrated ${entity.entityId}`);
  }
  
  console.log(`âœ… Migration complete: ${entities.length} files`);
}
```

---

### Phase 2: Add TimescaleDB for Events (Week 2)

**Steps**:
```
Day 1: Setup TimescaleDB instance OR enable on Neon
Day 2: Create hypertable schema
Day 3: Dual-write (PostgreSQL + TimescaleDB)
Day 4: Migrate historical events
Day 5: Switch reads to TimescaleDB
Day 6: Remove PostgreSQL events table
Day 7: Testing
```

**Code**:
```typescript
// packages/database/src/timescale-client.ts (NEW)
import { drizzle } from 'drizzle-orm/neon-serverless';
import { Pool } from '@neondatabase/serverless';

const pool = new Pool({ 
  connectionString: process.env.TIMESCALE_URL || process.env.DATABASE_URL
});

export const timescaleDb = drizzle(pool);

// Initialize hypertable
export async function initTimescale() {
  await pool.query(`
    CREATE EXTENSION IF NOT EXISTS timescaledb;
    
    SELECT create_hypertable(
      'events',
      'timestamp',
      if_not_exists => TRUE
    );
    
    SELECT add_compression_policy('events', INTERVAL '7 days');
    SELECT add_retention_policy('events', INTERVAL '2 years');
  `);
}
```

---

### Phase 3: Remove Storage Redundancy (Week 3)

**Steps**:
```
Day 1: Create Storage interface
Day 2: Implement PostgresStorage (no files)
Day 3: Update @initiativ/core to use interface
Day 4: Remove file operations from @initiativ/storage
Day 5: Testing
```

**Code**:
```typescript
// packages/@initiativ-core/src/storage-interface.ts (NEW)
export interface IStorage {
  createEntity(data: CreateEntityData): Promise<Entity>;
  getEntity(id: EntityId): Promise<Entity>;
  updateEntity(id: EntityId, data: Partial<Entity>): Promise<Entity>;
  deleteEntity(id: EntityId): Promise<void>;
  searchEntities(query: SearchQuery): Promise<Entity[]>;
}

// packages/api/src/storage/postgres-storage.ts (NEW)
export class PostgresStorage implements IStorage {
  constructor(
    private db: DrizzleDb,
    private r2: R2Storage
  ) {}
  
  async createEntity(data: CreateEntityData): Promise<Entity> {
    // 1. Upload content to R2
    const file = await this.r2.upload(
      `users/${data.userId}/notes/${data.id}.md`,
      data.content
    );
    
    // 2. Write event
    await this.db.append({
      eventType: EventType.ENTITY_CREATED,
      aggregateId: data.id,
      data: {
        type: data.type,
        title: data.title,
        fileUrl: file.url,
      },
    });
    
    // 3. Update projection (synchronous)
    const [entity] = await this.db.insert(entities).values({
      id: data.id,
      userId: data.userId,
      type: data.type,
      title: data.title,
      fileUrl: file.url,
      fileSize: file.size,
      checksum: file.checksum,
    }).returning();
    
    return entity;
  }
}

// @initiativ/core uses interface
class Workflows {
  constructor(private storage: IStorage) {}  // âœ… DI pattern
  
  async captureNote(input) {
    return await this.storage.createEntity({ ... });
  }
}
```

---

## ğŸ“Š Before vs After Comparison

### Data Flow: Create Note

#### âŒ Before (V0.2 - Redundant)

```
User: "Meeting notes"
  â†“
1. @initiativ/storage
   â”œâ”€ Write: notes/123.md (file)
   â””â”€ Write: SQLite cache
  â†“
2. @synap/api
   â””â”€ Write: events table (full data)
  â†“
3. Inngest projector
   â”œâ”€ Write: entities table
   â”œâ”€ Write: content_blocks table (content again!)
   â””â”€ Takes 500ms

Total: 5 writes, 500ms latency
Storage: 5x duplication
```

---

#### âœ… After (V0.3 - Clean)

```
User: "Meeting notes"
  â†“
1. API Handler
   â”œâ”€ Upload to R2: users/abc/notes/123.md
   â”‚  Returns: { url, size, checksum }
   â”œâ”€ Write event: { aggregateId: 123, data: { fileUrl } }
   â””â”€ Write entity: { id: 123, fileUrl, checksum }
  â†“
2. Async AI (Inngest)
   â”œâ”€ Download from R2
   â”œâ”€ Claude analysis
   â”œâ”€ Generate embedding
   â””â”€ Update entity: { title, tags }

Total: 3 writes, 200ms latency (2-3s async)
Storage: 1x (no duplication!)
```

**Improvements**:
- âœ… 70% fewer writes
- âœ… 60% faster response
- âœ… 80% storage reduction
- âœ… Clearer data flow

---

## ğŸ—ï¸ Final Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLIENT (Web/Mobile/CLI)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API LAYER (Hono + tRPC)                                         â”‚
â”‚  â€¢ Authentication (Better Auth)                                  â”‚
â”‚  â€¢ Input validation (Zod)                                        â”‚
â”‚  â€¢ Request handling                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼             â–¼              â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TimescaleDB  â”‚ â”‚ PostgreSQL   â”‚ â”‚ R2 Storage â”‚ â”‚ Inngest      â”‚
â”‚              â”‚ â”‚              â”‚ â”‚            â”‚ â”‚              â”‚
â”‚ â€¢ Events     â”‚ â”‚ â€¢ Entities   â”‚ â”‚ â€¢ Files    â”‚ â”‚ â€¢ AI Flows   â”‚
â”‚ (history)    â”‚ â”‚ â€¢ Relations  â”‚ â”‚ â€¢ Backups  â”‚ â”‚ â€¢ Complex    â”‚
â”‚              â”‚ â”‚ â€¢ Tags       â”‚ â”‚            â”‚ â”‚   Workflows  â”‚
â”‚ Append-only  â”‚ â”‚ Current Stateâ”‚ â”‚ Cheap Blob â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚              â”‚              â”‚
       â”‚                 â”‚              â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Redis Cache    â”‚
              â”‚   (Optional)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Search Index    â”‚
              â”‚  (pgvector or    â”‚
              â”‚   Qdrant)        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Principles**:
1. âœ… **Events**: Immutable history (TimescaleDB)
2. âœ… **Entities**: Current state (PostgreSQL)
3. âœ… **Files**: Actual content (R2)
4. âœ… **Relations**: Knowledge graph (PostgreSQL)
5. âœ… **Vectors**: Semantic search (pgvector/Qdrant)
6. âœ… **Cache**: Hot data (Redis - optional)

**No Redundancy**: Each piece of data stored ONCE!

---

## ğŸ¯ Standardization Guidelines

### Naming Conventions

**Tables**: `snake_case`, plural
```sql
events
entities
task_details
entity_vectors
```

**Columns**: `snake_case`, descriptive
```sql
aggregate_id (not: aggId, agg_id, objectId)
event_type (not: type, evt_type, kind)
file_url (not: url, fileURL, path)
```

**TypeScript**: `PascalCase` for types, `camelCase` for vars
```typescript
EntityType (enum)
Entity (interface)
entityId (variable)
createEntity (function)
```

**Events**: `{aggregate}.{action}[.{detail}]`
```
entity.created (not: EntityCreated, entity_created)
entity.title_changed (not: entity.updated, TitleChanged)
task.completed (not: task.done, TaskComplete)
```

---

### Type System Structure

```typescript
// packages/types/src/index.ts (NEW - Shared types)

// ===================================================================
// LEVEL 1: PRIMITIVE TYPES (Building Blocks)
// ===================================================================

export type UserId = string & { __brand: 'UserId' };
export type EntityId = string & { __brand: 'EntityId' };
export type EventId = string & { __brand: 'EventId' };

// ===================================================================
// LEVEL 2: ENUMS (Closed Sets)
// ===================================================================

export enum EntityType { ... }
export enum EventType { ... }
export enum FileType { ... }

// ===================================================================
// LEVEL 3: DOMAIN OBJECTS (Business Entities)
// ===================================================================

export interface Entity { ... }
export interface Event { ... }
export interface Relation { ... }

// ===================================================================
// LEVEL 4: VALUE OBJECTS (Immutable Data)
// ===================================================================

export interface FileReference {
  url: string;
  path: string;
  size: number;
  type: FileType;
  checksum: string;
  uploadedAt: Date;
}

export interface EventMetadata {
  ipAddress?: string;
  userAgent?: string;
  aiModel?: string;
  processingTime?: number;
}

// ===================================================================
// LEVEL 5: APPLICATION TYPES (DTOs, Requests)
// ===================================================================

export interface CreateNoteRequest {
  content: string;
  title?: string;
  tags?: string[];
}

export interface CreateNoteResponse {
  entity: Entity;
  fileUrl: string;
}
```

**Extensibility**:
- âœ… Add new enums: Just extend enum
- âœ… Add new fields: Optional properties
- âœ… Add new types: New interfaces

**Trade-Offs**:
- âœ… Centralized types (single source of truth)
- âš ï¸ All packages depend on @synap/types
- âœ… But: Zero duplication

---

## ğŸ§ª Testing Strategy

### Unit Tests (Per Module)

```typescript
// packages/storage/tests/r2.test.ts
describe('R2Storage', () => {
  it('should upload file and return metadata', async () => {
    const result = await r2.upload('test.md', 'content');
    expect(result.url).toMatch(/^https:\/\/r2\./);
    expect(result.size).toBe(7);
    expect(result.checksum).toMatch(/^sha256:/);
  });
});

// packages/database/tests/events.test.ts
describe('Events Repository', () => {
  it('should append event with correct structure', async () => {
    const event = await events.append({
      aggregateId: EntityId('123'),
      eventType: EventType.ENTITY_CREATED,
      data: { title: 'Test' },
    });
    
    expect(event.aggregateId).toBe('123');
    expect(event.version).toBe(1);
  });
  
  it('should reject event with wrong version (concurrency)', async () => {
    await expect(
      events.append({ aggregateId: '123', version: 5 })  // Skip versions
    ).rejects.toThrow('Concurrency conflict');
  });
});
```

---

### Integration Tests (Cross-Module)

```typescript
// packages/core/tests/note-creation.integration.test.ts
describe('Note Creation Workflow', () => {
  it('should create note with file on R2 and event in TimescaleDB', async () => {
    // Call API
    const response = await trpc.notes.create.mutate({
      content: 'Test note',
    });
    
    // Verify entity in PostgreSQL
    const entity = await db.select()
      .from(entities)
      .where(eq(entities.id, response.entityId));
    expect(entity.fileUrl).toMatch(/^https:\/\/r2\./);
    
    // Verify file on R2
    const content = await r2.download(entity.filePath);
    expect(content).toBe('Test note');
    
    // Verify event in TimescaleDB
    const events = await timescaleDb.select()
      .from(eventsTable)
      .where(eq(eventsTable.aggregateId, response.entityId));
    expect(events[0].eventType).toBe('entity.created');
    expect(events[0].data.fileUrl).toBe(entity.fileUrl);
  });
});
```

---

### E2E Tests (Full System)

```typescript
// e2e/tests/user-journey.test.ts
describe('User Journey: Capture Thought â†’ AI Enrichment', () => {
  it('should process thought end-to-end', async () => {
    // 1. User captures thought
    const capture = await trpc.capture.thought.mutate({
      content: 'Buy milk tomorrow',
    });
    
    expect(capture.success).toBe(true);
    
    // 2. Wait for AI processing
    await sleep(3000);
    
    // 3. Verify entity created
    const entities = await trpc.notes.search.query({
      query: 'milk',
    });
    
    expect(entities.length).toBeGreaterThan(0);
    expect(entities[0].type).toBe('task');  // AI detected intent
    expect(entities[0].title).toContain('milk');
    
    // 4. Verify file exists on R2
    const content = await r2.download(entities[0].filePath);
    expect(content).toBe('Buy milk tomorrow');
    
    // 5. Verify events logged
    const events = await getEvents(entities[0].id);
    expect(events).toHaveLength(2);  // created + ai_enriched
  });
});
```

---

## ğŸ’° Cost Analysis

### Current (V0.2)

```
10,000 users Ã— 1GB each = 10TB

PostgreSQL (with 5x redundancy):
- 50TB stored
- $0.23/GB = $11,500/month ğŸ”´

Inngest (unnecessary projectors):
- 1M function runs/month
- $100/month

Total: $11,600/month
Per user: $1.16/month
```

---

### Proposed (V0.3)

```
10,000 users Ã— 1GB each = 10TB

R2 Storage (content):
- 8TB (80% of data)
- $0.015/GB = $120/month âœ…

PostgreSQL (metadata only):
- 2TB (20% of data)  
- $0.23/GB = $460/month âœ…

TimescaleDB (events, compressed):
- 500GB (compressed 10x)
- $0.15/GB = $75/month âœ…

pgvector (search):
- Included in PostgreSQL

Inngest (complex workflows only):
- 100K function runs/month
- $25/month âœ…

Total: $680/month
Per user: $0.068/month

âœ… SAVINGS: $10,920/month (94%!)
```

**ROI**: Refactoring cost (3 weeks) paid back in 1 month!

---

## ğŸ¯ Decision Points

### Decision #1: TimescaleDB or EventStoreDB?

**Question**: Which time-series database?

**Options**:
- **A**: TimescaleDB (if Neon supports) âœ… Easier
- **B**: EventStoreDB (separate service) âœ… Better for event sourcing
- **C**: ClickHouse âš ï¸ Overkill

**Criteria**:
- Budget: TimescaleDB
- Scale (>10B events): EventStoreDB
- Event sourcing features: EventStoreDB
- Simplicity: TimescaleDB

**Recommendation**: **Start with TimescaleDB, migrate to EventStoreDB if needed**

---

### Decision #2: Sync or Async Projections?

**Question**: Should projections be synchronous or async?

**Option A**: Synchronous (in API request)
```typescript
await db.transaction(async (tx) => {
  await tx.append(event);       // Write event
  await tx.insert(entities);    // Update projection
});
// User sees data immediately
```

**Option B**: Async (via Inngest)
```typescript
await events.append(event);  // Write event
return { success: true };    // User gets response

// Later: Inngest updates projection
```

**Recommendation**: **HYBRID**
- Simple ops (CRUD): Synchronous âœ…
- Complex ops (AI, external APIs): Async âœ…

**Rationale**:
- User expects immediate feedback for simple ops
- User understands AI takes time

---

### Decision #3: pgvector or Qdrant?

**Question**: Where to store embeddings?

**Recommendation**: **pgvector for V0.3**
- Simpler (same database)
- Good enough for <1M vectors
- Migrate to Qdrant if needed later

---

### Decision #4: Keep @initiativ/* or Replace?

**Question**: Should we keep @initiativ/* packages?

**Analysis**:

**Keep @initiativ/core** âœ… (business logic)
- Workflows orchestration
- Domain logic
- BUT: Remove file storage dependency

**Replace @initiativ/storage** âš ï¸
- Currently duplicates data
- Should be interface â†’ PostgresStorage implementation

**Keep @initiativ/agents** âœ… (AI operations)
- Claude API calls
- Tag generation
- Title generation

**Keep @initiativ/rag** âœ… (semantic search)
- But: Use PostgreSQL vectors instead of separate index

**Keep @initiativ/input** âœ… (input processing)
- Audio transcription
- Text normalization

**Remove @initiativ/git** âš ï¸ (for now)
- Version control can be Phase 4
- R2 supports versioning natively

**Remove @initiativ/memory** âš ï¸ (redundant)
- Just use Redis cache

**Verdict**: Keep core logic, replace infrastructure

---

## ğŸ“‹ Implementation Checklist

### Week 1: R2 Storage

- [ ] Setup Cloudflare R2 bucket
- [ ] Implement R2Storage class
- [ ] Add file fields to entities table
- [ ] Migrate existing content to R2
- [ ] Remove content from content_blocks
- [ ] Drop content_blocks table
- [ ] Update API to upload to R2
- [ ] Testing

**Deliverable**: Content lives on R2, entities reference files

---

### Week 2: TimescaleDB Events

- [ ] Evaluate: Can Neon enable TimescaleDB?
- [ ] If yes: Enable extension
- [ ] If no: Setup separate TimescaleDB instance
- [ ] Create hypertable schema
- [ ] Implement EventRepository
- [ ] Dual-write for 2 days (validation)
- [ ] Migrate historical events
- [ ] Switch to TimescaleDB
- [ ] Drop PostgreSQL events table
- [ ] Testing

**Deliverable**: Events in time-series DB

---

### Week 3: Simplify Architecture

- [ ] Create IStorage interface
- [ ] Implement PostgresStorage
- [ ] Update @initiativ/core to use interface
- [ ] Remove @initiativ/storage file operations
- [ ] Remove simple Inngest projectors
- [ ] Update API to write projections synchronously
- [ ] Keep complex Inngest workflows (AI, etc.)
- [ ] Testing

**Deliverable**: Clean architecture, no redundancy

---

## ğŸ¯ Success Criteria

V0.3 is **complete** when:

### Functional
- [ ] All data accessible via API âœ…
- [ ] Events stored in time-series DB âœ…
- [ ] Content stored on R2 âœ…
- [ ] No storage redundancy âœ…
- [ ] Search still works âœ…

### Performance
- [ ] API response <200ms (vs 500ms current) âœ…
- [ ] Event append <50ms âœ…
- [ ] File upload <500ms âœ…
- [ ] Search <300ms âœ…

### Cost
- [ ] Storage cost reduced by 80% âœ…
- [ ] Function invocations reduced by 90% âœ…
- [ ] Total cost <$1000/month for 10K users âœ…

### Code Quality
- [ ] Zero storage redundancy âœ…
- [ ] Correct database for each data type âœ…
- [ ] Types & enums everywhere âœ…
- [ ] No `any` except multi-dialect (acceptable) âœ…

---

## ğŸ“ Learning from Mistakes

### What We Did Wrong in V0.2

1. âŒ **Assumed one database fits all**
   - Reality: Different data needs different storage

2. âŒ **Duplicated storage between systems**
   - @initiativ/* AND @synap/* both storing

3. âŒ **Used Inngest for simple operations**
   - Should be for complex workflows only

4. âŒ **Put content in relational DB**
   - Should be in object storage

5. âŒ **Stored full objects in events**
   - Should store deltas only

---

### What We'll Do Right in V0.3

1. âœ… **Right database for right data**
   - Events â†’ TimescaleDB
   - Metadata â†’ PostgreSQL  
   - Content â†’ R2
   - Vectors â†’ pgvector/Qdrant

2. âœ… **Single source of truth**
   - No duplication
   - Clear ownership

3. âœ… **Inngest for complex only**
   - AI workflows
   - External APIs
   - Multi-step processes

4. âœ… **Object storage for content**
   - Cheap
   - Scalable
   - CDN-friendly

5. âœ… **Events store deltas**
   - Small
   - Replayable
   - Audit trail

---

## ğŸ“Š Risk Assessment

### Migration Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Data loss during migration** | ğŸŸ¡ Medium | ğŸ”´ Critical | Dual-write period, backups |
| **Downtime** | ğŸŸ¡ Medium | ğŸŸ  High | Blue-green deployment |
| **Performance regression** | ğŸŸ¢ Low | ğŸŸ¡ Medium | Load testing before switch |
| **Cost overrun** | ğŸŸ¢ Low | ğŸŸ¡ Medium | Start small, scale gradually |
| **Bugs in new code** | ğŸŸ¡ Medium | ğŸŸ  High | Comprehensive tests, staged rollout |

**Overall Risk**: ğŸŸ¡ **Medium** (manageable with proper planning)

---

## ğŸ’¡ Final Recommendations

### For Approval

**Proposed Changes**:
1. âœ… Remove content_blocks table â†’ R2 files
2. âœ… Migrate events to TimescaleDB
3. âœ… Make @initiativ/storage an interface
4. âœ… Sync projections for simple ops
5. âœ… Async (Inngest) only for complex workflows

**Timeline**: 3 weeks  
**Cost Reduction**: 94% ($11,600 â†’ $680/month)  
**Storage Reduction**: 80% (50TB â†’ 10TB)  
**Performance Improvement**: 60% faster (500ms â†’ 200ms)  

**Risk**: ğŸŸ¡ Medium (but well-mitigated)

---

### Questions for You

Before we proceed, please decide:

1. **TimescaleDB or EventStoreDB?**
   - Check if Neon supports TimescaleDB
   - Or budget for separate EventStoreDB instance?

2. **Migration timeline?**
   - Fast (3 weeks, some risk)
   - Safe (6 weeks, minimal risk)

3. **R2 or S3?**
   - Cloudflare R2 (cheaper, recommended)
   - AWS S3 (more features)

4. **pgvector or Qdrant?**
   - pgvector (simpler)
   - Qdrant (better performance)

---

**Status**: ğŸŸ¡ **Awaiting your approval to proceed with V0.3 refactoring**

**Next**: You review â†’ Approve â†’ We implement (3 weeks)

