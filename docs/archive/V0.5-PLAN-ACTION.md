# Plan d’Action V0.5 — Activation de l’Intelligence

## 1. Nouvel état des lieux (Vision vs Réalité)

| Pilier du manifeste | Attendu selon le manifeste | État actuel (V0.4 / LangGraph V0.5 skeleton) | Écart principal |
| --- | --- | --- | --- |
| Capture sans jugement | Interface conversationnelle unique, zéro friction, multimodal (texte/voix/image), conversation proactive | `chat.sendMessage` → stockage message + réponse AI (texte uniquement). Pas encore branché sur LangGraph. Pas de voix/images. Réaction uniquement quand l’utilisateur parle. | Manque d’unification UI autour du chat; absence de multimodal; agent non proactif. |
| Organisation ambiante | Agents silencieux qui classent, relient, infèrent; Super Memory enrichie automatiquement; outils analysant relations | Toolbox = `createEntity`, `semanticSearch`. Pas de tagging auto, pas de corrélations, pas de mémoire durable dans prompts. | Manque d’outils analytiques (graph de connaissances, embeddings actualisés); aucune boucle de réflexion périodique; pas de Super Memory branchée. |
| Révélation | Suggestions proactives (“Inbox IA”), détection de patterns, rappels contextuels, initiatives | Aucun canal de suggestions; workflow purement synchrone; pas de planification en arrière-plan ni d’événements proactifs. | Besoin d’un orchestrateur pour tâches différées, table ou bus d’événements “insights”, moteur de scoring pour prioriser. |
| Cercles de réflexion | Boucles où l’IA vérifie, planifie, améliore sans sollicitation immédiate | LangGraph exécute un seul cycle message → plan → exécution → réponse. Pas de workflows déclenchés par le temps/événements. | Introduire tâches asynchrones (Inngest ou Cron orchestré), checkpoints, states persistants. |
| Personnalisation profonde | Super Memory (faits user, préférences) injectée dans prompts et décisions | `gather_context` n’utilise que recherche basique. Aucun profil utilisateur exploité. | Définir schéma mémoire, pipelines d’alimentation, règles de prompt. |
| UX globale | Chat + tableau de bord qui montre révélations et suggestions | UX côté frontend non traité dans cette phase. | Nécessite API pour “IA Inbox”, flux websockets. |


## 2. Architecture cible pour `@synap/ai`

### 2.1 Vision “Cerveau en 3 Systèmes”

- **Perception (Capture & Contextualisation)**  
  - Sources: Entrées utilisateur (chat, voix future), webhooks, emails.  
  - Modules: `conversation-messages`, transcription service, ingestion pipeline.  
  - Fonctions: Normaliser messages, enrichir métadonnées, stocker bruts avant toute structuration.
- **Raison (LangGraph Orchestrator)**  
  - Graphe principal (déjà amorcé): `parse_intent`, `gather_context`, `plan_actions`, `execute_actions`, `generate_final_response`.  
  - Étendues prévues:
    - **Branches proactives**: nœuds “Reflection Loop” déclenchés en différé (cron) qui relancent `plan_actions` avec objectifs internes (ex: “identifier doublons”).  
    - **Sub-graphs spécialisés**: planificateur créatif, correcteur de mémoire, veille.  
    - **Task queue**: via Inngest pour lancer des graphes hors ligne.
- **Intuition (Révélation & Proactivité)**  
  - Super Memory: base de faits (`user_facts`, `relationships`) alimentée par Raison.  
  - Insight Engine: process batch/stream qui scanne mémoire + événements, produit recommandations.  
  - IA Inbox: table `ai_suggestions` (SQL) ou stream d’événements `agent.insight.created`. Consommé par UI + notifications.  

### 2.2 Diagramme de flux (simplifié)

```mermaid
flowchart LR
    subgraph Perception
        A[Chat Input / Voice / API] --> B[Ingestion Layer]
        B --> C[Conversation Store]
    end

    subgraph Raison (LangGraph)
        C --> D[parse_intent]
        D --> E[gather_context]
        E --> F[plan_actions]
        F --> G[execute_actions]
        G --> H[generate_final_response]
        G --> I[Super Memory Updater]
    end

    subgraph Intuition
        I --> J[Super Memory DB]
        J --> K[Insight Engine]
        K --> L[IA Inbox (ai_suggestions)]
        L --> M[Frontend Notifications]
    end

    H --> N[User Response]
    K --> F
```

### 2.3 Super Memory

- **Stockage**: tables dédiées (ex: `user_profiles`, `user_preferences`, `knowledge_facts`, `insight_journal`).  
- **Alimentation**:  
  - Après chaque `execute_actions`, pipeline `Super Memory Updater` extrait faits (ex: “User aime format mind-map”).  
  - Jobs réguliers (Inngest) ré-embeddings & clustering pour connexions.  
- **Utilisation dans prompts**:  
  - `gather_context` charge top N facts pertinents + signale préférences (ton, format).  
  - Planner & responder lisent ces facts pour adapter outputs.

### 2.4 Proactivité & Inbox IA

- **Stratégie**:
  - `Insight Engine` fonctionne comme agent LangGraph secondaire (planifications basées sur triggers temps/événements).  
  - Quand une suggestion forte est trouvée: écrit dans `ai_suggestions` (id, userId, type, payload, score, status).  
  - UI consomme via tRPC `suggestions.list`, `suggestions.acknowledge`, `suggestions.execute`.  
  - Option: aussi émettre événement `agent.insight.created` dans Timescale pour audit.

### 2.5 Rôle du Vercel AI SDK vs LangChain/LangGraph

- **LangChain/LangGraph**: cerveau backend. Build-in orchestration, tool calling, stateful workflows, proactivité.  
- **Vercel AI SDK**:  
  - Côté frontend/API streaming (UI) pour afficher token par token.  
  - Pour prompts frontaux (UI builder) ou fallback direct.  
- **Interaction**:  
  - Backend (LangGraph) produit réponse finale + métadonnées.  
  - API renvoie streaming via Vercel SDK si besoin, en s’appuyant sur `generateResponseStream` existant ou future `synapAgentGraph.stream`.  
  - Maintenir un seul moteur principal (LangGraph) pour décisions; Vercel SDK reste un adaptateur UI.


## 3. Roadmap technique détaillée

### Phase A — Alignement Capture (post-V0.4)
1. **Brancher `chat.sendMessage` sur `runSynapAgent`**  
   - Pourquoi: réaliser “Capture sans jugement” → la conversation devient l’unique interface.  
   - Tâches: refactor tRPC, stocker `plan`, `executionSummaries`, `intentAnalysis`.  
2. **Streaming UI (optionnel)**  
   - Utiliser Vercel AI SDK côté frontend pour afficher réponses progressives; backend garde LangGraph.  
   - Principe: fluidité, suppression de friction.

### Phase B — Organisation ambiante (outils & mémoire)
3. **Créer Super Memory schemas** (`knowledge_facts`, `user_signals`, `ai_suggestions`)  
   - Raison: matérialiser l’intuition que le système “se souvient et relie”.  
4. **Étendre toolbox**  
   - `analyzeNoteRelationshipsTool`, `autoTagTool`, `summarizeThreadTool`.  
   - Brancher dans LangGraph plan actions.  
5. **Context loader enrichi**  
   - `gather_context` récupère: conversation récente + `knowledge_facts` pertinents + embeddings.  

### Phase C — Proactivité & révélation
6. **Insight Engine (LangGraph subgraph)**  
   - Cron/Inngest déclenche sous-graphe `reflection_loop`:  
     - Extrait nouvelles notes/tâches;  
     - Analyse patterns;  
     - Alimente `ai_suggestions`.  
   - Manifesto: effet “bibliothécaire invisible” + “Aha moment”.  
7. **IA Inbox API & UI**  
   - tRPC `suggestions.list/ack/execute`.  
   - Front: panneau notifications.  
8. **Proactive messaging**  
   - Option: chat message automatique “J’ai trouvé une connexion...”.  

### Phase D — Qualité & cohérence
9. **Test harness**  
   - Mock Anthropic, valider graph transitions, ensure deterministic tool execution.  
10. **Observabilité**  
    - Traces pour chaque node (time, tokens, tool usage).  
    - Dashboard (Grafana) pour proactivité pipeline.  
11. **Security & governance**  
    - Rate limits sur proactivité, contrôle RGPD des Super Memory facts, audit logs Timescale.

### Phase E — Extensions (post-V0.5 core)
12. **Multimodal perception**  
    - Intégrer audio → texte, images → notes automatiques (Later).  
13. **Team spaces**  
    - Partage d’idées, suggestions croisés multi-utilisateurs.  


## Conclusion

Nous avons maintenant:
- Une vision claire alignée sur le manifeste.  
- Une architecture en “Perception / Raison / Intuition” positionnant LangGraph comme cerveau et la Super Memory comme âme.  
- Une roadmap justifiée par les piliers “Capture, Organisation, Révélation”.  

Prochain pas: implémenter Phase A (brancher `chat.sendMessage`), puis enchaîner sur les briques mémoire et proactivité. Restons fidèles au manifeste: zéro friction, agent silencieux, moments “Aha!”.  

